{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab18a19d",
   "metadata": {},
   "source": [
    "### Matthew Thompson\n",
    "\n",
    "### Assignment 1\n",
    "\n",
    "#### CAP 6676 Information Retrieval\n",
    "\n",
    "\n",
    "Tasks:\n",
    "\n",
    "- Install Python and NLTK (3 points)\n",
    "\n",
    "- Tokenize the documents into words, remove stop words, and conduct stemming (5 points)\n",
    "\n",
    "- Calculate tf-idf for each word in each document and generate document-word matrix (each element in the matrix is the tf-idf score for a word in a document) (7 points)\n",
    "\n",
    "- Calculate pairwise cosine similarity for the documents (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64e3e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, glob, os, re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765c34f",
   "metadata": {},
   "source": [
    "Tokenize into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "997cd74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_texts():\n",
    "    \"\"\"load texts from directory: return dictionary of texts\"\"\"\n",
    "    \n",
    "    docs = {}\n",
    "    files = glob.glob(os.path.join(os.getcwd(), '*.txt'))\n",
    "    for file in files:\n",
    "        full_file_name = os.path.split(file)[-1]\n",
    "        file_name = full_file_name.split('.')[0]\n",
    "#         print(file_name)\n",
    "        with open(file, 'r') as read_file:\n",
    "            text = read_file.readlines()\n",
    "            join_lines = ' '.join(text)\n",
    "            strip_nl = [x.lower().strip() for x in join_lines.split()]\n",
    "            docs[file_name] = ' '.join(strip_nl)\n",
    "    return docs\n",
    "\n",
    "# load_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c72111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_remove_stopwords_stem(doc_name, doc_text):\n",
    "    \"\"\"returns tokenized, stemmed text, without stop words\"\"\"\n",
    "    \n",
    "#     results = {}\n",
    "    text_no_punct = re.sub(r'[^\\w\\s]','', doc_text)\n",
    "    tokenized_text = nltk.word_tokenize(text_no_punct)\n",
    "    no_stopwords = [x for x in tokenized_text if x not in stopwords.words('english')]\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed = [stemmer.stem(x) for x in no_stopwords]\n",
    "#     results[doc_name] = stemmed\n",
    "\n",
    "    return stemmed, tokenized_text, no_stopwords\n",
    "\n",
    "# docs = load_texts()\n",
    "# tokenize_remove_stopwords_stem('100618newsML', docs['100618newsML'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a168286c",
   "metadata": {},
   "source": [
    "Calculate tf-idf and generate document word matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "326a99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer\n",
    "\n",
    "def tfidf_vect(docs):\n",
    "    \"\"\"creates tf-idf vector for all docs\"\"\"\n",
    "    \n",
    "    # create order\n",
    "    doc_names = []\n",
    "    doc_text = []\n",
    "    for k,v in docs.items():\n",
    "        doc_names.append(k)\n",
    "        doc_text.append(v)\n",
    "    all_text =  doc_text\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_vect = vectorizer.fit_transform(all_text)\n",
    "    vocab = vectorizer.get_feature_names_out()\n",
    "    tf_idf_ = pd.DataFrame(index = [vocab])\n",
    "    for i, doc_name in enumerate(doc_names):\n",
    "#         tf_idf_[doc_name] = np.zeros(tf_idf_.shape[0]) #works so why doesn't it populate with the actual data?\n",
    "        tf_idf_[doc_name] = tfidf_vect.toarray()[i]\n",
    "\n",
    "    return tf_idf_\n",
    "\n",
    "\n",
    "# tfidf_vect(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9c1fb5",
   "metadata": {},
   "source": [
    "Calculate pairwise cosine similarity for the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc8f022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(df):\n",
    "    \"\"\"creates matrix of cosine similarities\"\"\"\n",
    "    \n",
    "    cols = df.columns\n",
    "    results = [\"Document : Document : Cosine similarity\"]\n",
    "#     cos_sim_matrix = pd.DataFrame({'doc': cols})\n",
    "    for i, col in enumerate(cols):\n",
    "        q = np.reshape(np.array(df[col]), (1, -1))\n",
    "        for j in (cols):\n",
    "#             q = np.reshape(np.array(df.loc[i, col]), (1, -1))\n",
    "            p = np.reshape(np.array(df[j]), (1, -1))\n",
    "            cos_sim = cosine_similarity(q, p)\n",
    "            if col == j:\n",
    "                continue\n",
    "            else:\n",
    "                results.append(f\"{col} : {j} : {cos_sim}\")\n",
    "    return results\n",
    "\n",
    "# cos_sim(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca66ffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim_calc(q, d):\n",
    "    \"\"\"calculates cosine similarity between vectors\"\"\"\n",
    "\n",
    "    euclid = lambda x: np.linalg.norm(x)\n",
    "    # skip calc if ==\n",
    "    if np.all(q == d):\n",
    "        return 1\n",
    "\n",
    "    dot_prod = np.dot(q,d)\n",
    "    denom = euclid(q) * euclid(d)\n",
    "\n",
    "    # avoid /0\n",
    "    if np.isclose(denom, 0, atol = 1e-32):\n",
    "        sim = 0\n",
    "    else:\n",
    "        sim = dot_prod / denom\n",
    "        \n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db485b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100554newsML</th>\n",
       "      <th>100593newsML</th>\n",
       "      <th>100618newsML</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100554newsML</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728454</td>\n",
       "      <td>0.754437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100593newsML</th>\n",
       "      <td>0.728454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100618newsML</th>\n",
       "      <td>0.754437</td>\n",
       "      <td>0.974443</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              100554newsML  100593newsML  100618newsML\n",
       "100554newsML      1.000000      0.728454      0.754437\n",
       "100593newsML      0.728454      1.000000      0.974443\n",
       "100618newsML      0.754437      0.974443      1.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cos_sim_matrix(df):\n",
    "    \"\"\"creates matrix of cosine similarities\"\"\"\n",
    "    \n",
    "    cols = df.columns\n",
    "    sim_matrix = pd.DataFrame()\n",
    "        \n",
    "    for i, col in enumerate(cols):\n",
    "        for j, row in enumerate(cols):\n",
    "            sim_matrix.loc[row, col] = cos_sim_calc(df[row], df[col])\n",
    "    \n",
    "    return sim_matrix\n",
    "\n",
    "cos_sim_matrix(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b7e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        test.loc[i,j] = j + i\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "412d33ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        100554newsML  100593newsML  100618newsML\n",
       " 10          0.052176      0.069287      0.072361\n",
       " 1040        0.026088      0.034644      0.036180\n",
       " 1135        0.026088      0.034644      0.036180\n",
       " 130         0.026088      0.034644      0.036180\n",
       " 136         0.000000      0.058657      0.000000\n",
       " ...              ...           ...           ...\n",
       " work        0.026088      0.034644      0.036180\n",
       " would       0.182618      0.138574      0.144722\n",
       " wrangl      0.000000      0.044610      0.046589\n",
       " wrestl      0.026088      0.034644      0.036180\n",
       " year        0.156529      0.034644      0.036180\n",
       " \n",
       " [271 rows x 3 columns],\n",
       " ['Document : Document : Cosine similarity',\n",
       "  '100554newsML : 100593newsML : [[0.72845372]]',\n",
       "  '100554newsML : 100618newsML : [[0.75443741]]',\n",
       "  '100593newsML : 100554newsML : [[0.72845372]]',\n",
       "  '100593newsML : 100618newsML : [[0.97444338]]',\n",
       "  '100618newsML : 100554newsML : [[0.75443741]]',\n",
       "  '100618newsML : 100593newsML : [[0.97444338]]'],\n",
       "               100554newsML  100593newsML  100618newsML\n",
       " 100554newsML      1.000000      0.728454      0.754437\n",
       " 100593newsML      0.728454      1.000000      0.974443\n",
       " 100618newsML      0.754437      0.974443      1.000000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"runs text processing\"\"\"\n",
    "    \n",
    "    docs = load_texts()\n",
    "    cleaned_docs = {}\n",
    "    for doc, text in docs.items():\n",
    "        token_nostop_stem = tokenize_remove_stopwords_stem(doc, text)\n",
    "        cleaned_docs[doc] = ' '.join(token_nostop_stem[0])#.values()\n",
    "#     print(cleaned_docs)\n",
    "    tf_idf = tfidf_vect(cleaned_docs)\n",
    "#     return tf_idf\n",
    "    cosine_sim_print = cos_sim(tf_idf)\n",
    "    corr_matrix = cos_sim_matrix(tf_idf)\n",
    "    return tf_idf, cosine_sim_print, corr_matrix\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de338e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
